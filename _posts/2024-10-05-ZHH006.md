---
title: ZHH-006
paper: "Improved Variational Inference with Inverse Autoregressive Flow"
paper_url: "https://arxiv.org/abs/1606.04934"
paper_year: 2016
tags: 
    - Flow
    - VAE
    - NotImplementedError
layout: post
---

NotImplementedError: 对于这篇文章，我们的理解还存在不同。以下只是我的理解。

TLDR: 核心思想仍然是使用Flow model来改进VAE中 $q(z|x)$ 的近似。相比于Normalizing Flow，IAF的好处是它的表现力更强；相比于 Autoregressive Flow （比如 [MADE](https://arxiv.org/abs/1502.03509)），IAF的好处是它的计算效率更高。此外，作者还提出了“Resnet VAE”的结构（还没理解？）

对于AF，从一开始的输入 $u$ 经历一系列变换到输出 $v$，这个过程是快的；但是从 $v$ 反向计算 $u$ 的过程是慢的。而IAF中，从 $u$ 到 $v$ 的过程是慢的，但是反向计算是快的。而如果我们写出VAE的 ELBO loss：

$$
\text{ELBO}(x) = \mathbb{E}_{z\sim q(z|x)}\left[\log \frac{p(z)p(x|z)}{q(z|x)}\right]
$$

可以发现，如果我们在上面的 **IAF** 中，formulize $v$ 为用 $x$ encode的某种hidden，再加上噪声（即 $v=f(x)+\epsilon, \epsilon \sim r_\text{noise}(\epsilon)$ ，$r_\text{noise}$ 定义为噪声分布），然后 $u$ 为 $z$，那么我们发现刚好：loss可以写为

$$
\text{ELBO}(x) = \mathbb{E}_{\epsilon \sim r_\text{noise}(\epsilon)}\left[\log \frac{p(z)p(x|z)}{r_\text{noise}(\epsilon)\cdot (\det \frac{\partial u}{\partial v})^{-1}}\right]
$$

我们发现，没有需要从 $v$ 反向计算 $u$ 的过程！这样，我们同时兼得了计算效率和表现力。