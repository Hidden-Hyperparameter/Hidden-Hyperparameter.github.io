---
title: ZHH-009
paper: "Language Model Beats Diffusion -- Tokenizer is Key to Visual Generation"
paper_url: "https://arxiv.org/abs/2310.05737"
paper_year: 2023
tags: 
    - Tokenizer
    - Discrete
    - Transformer
    - Video
layout: post
---

使用Transformer来将视频进行encode，并且同时支持视频和图片。此外，作者提出 **LFQ** (Lookup-Free Quantization)，这相当于把原来的 $d$ 维 nearest-neighbor换成了把每一个token（ $d$ 维）映射到其在 $d$ 维空间的哪一个卦限（共 $2^d$ 个）。这样的好处是增大Vocab size的时候reconstruction quality还会上升，有利于运用LLM学习latent。

在细节上，因为 $2^d$ 通常还是太大了，所以要设法减少这个Vocab size，使得它和自然语言的合理范围相近（几万）。同时，直接这样训练是不行的，还需要加入entropy-loss，保证字典利用效率。