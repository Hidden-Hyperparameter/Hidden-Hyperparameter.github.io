---
title: ZHH-012
paper: "Show-o: One Single Transformer to Unify Multimodal Understanding and Generation"
paper_url: "https://arxiv.org/abs/2408.12528"
paper_year: 2024
tags: 
    - Transformer
    - Diffusion
layout: post
---

图片和文本的latent放在同一个transformer里；对于文本，目标是next-token prediction；而对于图片，是MaskGIT目标（预测 masked token）。在生成的时候，如果是文本，就是标准的autoregressive；而如果是图片，就开始mask-GIT式的生成。