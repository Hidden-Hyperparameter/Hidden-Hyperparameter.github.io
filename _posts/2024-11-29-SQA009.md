---
title: SQA-009
paper: "SCORE-BASED GENERATIVE MODELING THROUGH STOCHASTIC DIFFERENTIAL EQUATIONS"
paper_url: "https://arxiv.org/abs/2011.13456" 
paper_year: 2021
tags: 
    - "Diffusion"
layout: post
---

本文把 DDPM & NCSN formulate 成 SED 的形式, 并提出了 reverse SDE 和 ODE.

Instead of discrete time steps, consider a __continuum__ of distributions.

网络学习的仍然是 score function.

## VP SDE (Variance Preserving)

DDPM 的 Markov Chain: (where $z\sim \mathcal N(0, I)$)
$$
x_i = \sqrt{1-\beta_i}x_{i-1}+\sqrt{\beta_i}z_{i-1}
$$
连续化成 SDE:
$$
dx = -\frac 12\beta(t)xdt + \sqrt{\beta(t)}dw
$$

## VE SDE (Variance Exploding)

SMLD / NCSN 的 Markov Chain:
$$
x_i = x_{i-1}+\sqrt{\sigma_i^2-\sigma_{i-1}^2}z_{i-1}
$$
连续化成 SDE:
$$
dx = \sqrt{\frac{d[\sigma^2(t)]}{dt}}dw
$$

## sub-VP SDE
本文提出了一个新的 SDE
$$
dx = -\frac 12\beta(t)xdt + \sqrt{\beta(t)(1-\exp(-2\int_0^t \beta(s)ds))}dw
$$

可以看出, 这个 SDE 只是 VP SDE 的噪声变小一点. 可以证明, 该 SDE 的 variance 不超过 VP SDE 的 variance.

作者声称这个 SDE work very well.

## Sampling method

本文提到了很多 sample (解 reverse SDE) 的方法, 比如 `Euler-Maruyama and stochastic Runge-Kutta methods`. 

对于 DDPM 原来的 `ancestor sampling`, 本文提出了 `reverse-time sampling`, 对其进行改进. 想看的看 Appendix E.

本文还提出了 __Predictor-Corrector__ 的方法. 其核心想法是, 每次我们的 predictor (SDE solver) 做一步, 然后用我们的 corrector (比如 langevin MCMC) 来修正.

![image not found](/papers/SQA-009/PC.png) 

看起来使用的步数很多, 但是效果不错. 毕竟只是21年的论文.

本文也发现了 ODE sampling 是 uniquely determined by data distribution 的.

## Architecture Improvement

NCSN++ 和 DDPM++ 都是这里提出的. __弱__

虽然里面好像说 DDPM++ 和 NCSN++ 都把网络深度翻倍了.

实验结果是, __VE SDE__ 能比 VP/sub-VP 达到更好的 FID & IS, 但是 NLL 更差.

## Controllable generation

对于 conditional generation $p_t(x(t)\mid y)$, 可以用下面的公式 reverse SDE:
$$
dx = (f(x, t)-g(t)^2 [\nabla_x \log p_t(x)+\nabla_x \log p_t(y\mid x)])dt + g(t)dw
$$
这样声称可以做 conditional generation & inpainting & Colorization.

好像还提出了可以不用重新训练的方法, 详见 Appendix I.4